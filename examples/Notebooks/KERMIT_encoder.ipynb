{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using KERMIT - Building dataset -\n",
    "\n",
    "This first notebook explains how to construct the syntactic input for KERMIT_system via KERMIT encoder.\n",
    "\n",
    "There are also links from where to download used datasets or you can use a dataset of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages\n",
    "Before starting, it is essential to have the following requirements:\n",
    "- stanford-corenlp-full-2018-10-05 : which will be used to build the trees in parenthetical form.\n",
    "- KERMIT : that it is obvious to have it but we specify it anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install stanfordcorenlp \n",
    "#!pip install stanfordcorenlp\n",
    "#!wget http://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip\n",
    "#!unzip stanford-corenlp-full-2018-10-05.zip\n",
    "\n",
    "#Install KERMIT\n",
    "#!git clone https://github.com/ART-Group-it/kerMIT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, pickle, ast, os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#script for reading/writing trees\n",
    "from scripts.script import readP, writeTree\n",
    "#script for build DTK\n",
    "from scripts.script import createDTK\n",
    "#script for parse sentences\n",
    "from scripts.script import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download  Dataset\n",
    "\n",
    "The datasets used in our work have been randomly sampled as follows:\n",
    "\n",
    "* *Note: in this tutorial we use ag_news (train and test set) but remember that the user can choose others as he prefers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download dataset ag_news\n",
    "\n",
    "#!wget wget https://data.deepai.org/agnews.zip\n",
    "#!unzip agnews.zip\n",
    "\n",
    "#! wget \"https://multi-classification.s3.eu-central-1.amazonaws.com/dbpedia_csv.tar.gz\"\n",
    "#! wget \"https://multi-classification.s3.eu-central-1.amazonaws.com/yelp_review_polarity_csv.tar.gz\"\n",
    "#! wget \"https://multi-classification.s3.eu-central-1.amazonaws.com/yelp_review_full_csv.tar.gz\"\n",
    "\n",
    "data_train = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "#if you want to sample the dataset in this way you exchange the examples and then take the first n lines\n",
    "\n",
    "#data = data_original.iloc[np.random.permutation(len(data_original))]\n",
    "#data = data[:70000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index                                              Title  \\\n",
       "0            3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1            3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2            3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3            3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4            3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         Description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building parenthetical trees and encode in Universal Syntactic Embeddings\n",
    "Here the loaded dataset is processed, transformed into tree form and encoded via kerMIT encoder.\n",
    "\n",
    "\n",
    "In realtime the trees are saved on file, a log file is made showing the number of processed rows of the dataset and the encoded trees are saved in pickle format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building parenthetical trees for Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert here your dataset name\n",
    "dataset_name = 'ag_news_train'\n",
    "\n",
    "\n",
    "name = 'dtk_trees_'+dataset_name+'.pkl'\n",
    "name2 = 'log_'+dataset_name+'.txt'\n",
    "name3 = 'dt_'+dataset_name+'.txt'\n",
    "\n",
    "i = 0\n",
    "cont = 0\n",
    "listTree = []\n",
    "newList = []\n",
    "oldList = []\n",
    "\n",
    "tree = \"(S)\"\n",
    "treeException = createDTK(tree)\n",
    "\n",
    "\n",
    "for line in tqdm(data_train['Description']):\n",
    "    cont += 1\n",
    "    try: \n",
    "        tree = (parse(line))\n",
    "        treeDTK = createDTK(tree)\n",
    "    except Exception:\n",
    "        tree, treeDTK = \"(S)\", treeException\n",
    "    \n",
    "    listTree.append(treeDTK)   \n",
    "    #write parenthetical tree\n",
    "    writeTree(name3,tree)\n",
    "    #every 5000 shafts saves the corresponding DTKs\n",
    "    if i>5000:\n",
    "        time.sleep(1)\n",
    "        if os.path.isfile(name):\n",
    "            #append new encoded tree in pickle file            \n",
    "            oldList = readP(name) \n",
    "            newList = oldList+listTree\n",
    "        else:\n",
    "            newList = listTree\n",
    "        \n",
    "        f=open(name, 'wb')\n",
    "        \n",
    "        for x in newList:\n",
    "            pickle.dump(x, f)\n",
    "        f.close()\n",
    "\n",
    "        f=open(name2, \"a+\")\n",
    "        f.write(str(cont)+'..')\n",
    "        f.close()\n",
    "                  \n",
    "        i = 0\n",
    "        listTree = []\n",
    "        newList = []\n",
    "        oldList = []         \n",
    "    else:\n",
    "        i +=1\n",
    "\n",
    "#checking consistency\n",
    "if os.path.isfile(name):\n",
    "    oldList = readP(name) \n",
    "    newList = oldList+listTree\n",
    "else:\n",
    "    newList = listTree      \n",
    "f=open(name, 'wb')\n",
    "for x in newList:\n",
    "    pickle.dump(x, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building parenthetical trees for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert here your dataset name\n",
    "dataset_name = 'ag_news_test'\n",
    "\n",
    "\n",
    "name = 'dtk_trees_'+dataset_name+'.pkl'\n",
    "name2 = 'log_'+dataset_name+'.txt'\n",
    "name3 = 'dt_'+dataset_name+'.txt'\n",
    "\n",
    "i = 0\n",
    "cont = 0\n",
    "listTree = []\n",
    "newList = []\n",
    "oldList = []\n",
    "\n",
    "tree = \"(S)\"\n",
    "treeException = createDTK(tree)\n",
    "\n",
    "\n",
    "for line in tqdm(data_test['Description']):\n",
    "    cont += 1\n",
    "    try: \n",
    "        tree = (parse(line))\n",
    "        treeDTK = createDTK(tree)\n",
    "    except Exception:\n",
    "        tree, treeDTK = \"(S)\", treeException\n",
    "    \n",
    "    listTree.append(treeDTK)   \n",
    "    #write parenthetical tree\n",
    "    writeTree(name3,tree)\n",
    "    #every 5000 shafts saves the corresponding DTKs\n",
    "    if i>5000:\n",
    "        time.sleep(1)\n",
    "        if os.path.isfile(name):\n",
    "            #append new encoded tree in pickle file\n",
    "            oldList = readP(name) \n",
    "            newList = oldList+listTree\n",
    "        else:\n",
    "            newList = listTree\n",
    "        \n",
    "        f=open(name, 'wb')\n",
    "        \n",
    "        for x in newList:\n",
    "            pickle.dump(x, f)\n",
    "        f.close()\n",
    "\n",
    "        f=open(name2, \"a+\")\n",
    "        f.write(str(cont)+'..')\n",
    "        f.close()\n",
    "                  \n",
    "        i = 0\n",
    "        listTree = []\n",
    "        newList = []\n",
    "        oldList = []         \n",
    "    else:\n",
    "        i +=1\n",
    "\n",
    "#checking consistency\n",
    "if os.path.isfile(name):\n",
    "    oldList = readP(name) \n",
    "    newList = oldList+listTree\n",
    "else:\n",
    "    newList = listTree      \n",
    "f=open(name, 'wb')\n",
    "for x in newList:\n",
    "    pickle.dump(x, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
